## [CH04_02] 프롬프팅테크닉 Top 7

### Few-shot examples
- 모델에게 몇가지 예시 제공
- 그 예시를 참고하여 답변을 하도록 함
- 성능 향상
- 종류
  - Zero shot: 예제를 제공하지 x
  - One shot: 한 개의 예제 제공
  - Few shot: 두 개 이상의 예제 제공
- Zero shot, Few shot에서 큰 성능 차이는 없겠으나
  - 번역하는 스타일 변경등에 활용 가능

#### Zero shot
```bash
Translate English to French: # task description
cheese => # Prompt
```

#### One shot
```bash
Translate English to French: # task description
sea otter => loutre de mer # example
cheese => # prompt
```

#### Few shot
```bash
Translate English to French: # task description
sea otter => loutre de mer # examples
peppermint => menthe poivree # examples
plush girafe => girafe peluche # examples
cheese => # prompt
```
- Few shot example은 parameter가 큰 모델에서 효과적
- **Few shot 제약 사항**
  - 충분히 큰 모델에서만 유의미하게 작동
  - **산술 추론 문제**에는 적합하지 x
  - 정답을 정확히 주기보다 **레이블의 랜덤한 분포**를 가진것이 나옴
    - 샘플의 내용이나 논리가 아닌, **형식**만 참고

### Chain of Thought
- LLM에게
  - **이유에 대해서 설명하도록 만들어, 답을 더 정확하게 생성하도록 만드는 기술**
- 중간 추론 단계를 거치도록 하여
  - 복잡한 사고가 필요한 작업에 정확도 향상
- 답이 나오는 과정에 대해 설명한 예시를 보여주고,
  - 지시에 대한 답을 생성할 때
  - **예시와 동일한 방식으로 그에 대한 과정을 설명하도록 만듦**
- **생각에 대한 과정을 제공한다**

#### 잘못된 예시
```md
# prompt
Q: 철수는 테니스공 5개를 가지고 있습니다. 철수는 테니스공을 담은 통을 2개 더 샀는데, 각 통에는 테니스공 3개가 있습니다. 철수는 이제 몇 개의 테니스공을 가지고 있을까요?
A: 정답은 11개 입니다.

Q: 식당에 사과가 23개 있었습니다. 점심을 만들기 위해 20개를 사용하고 6개를 더 산 뒤 3 개를 먹었다면, 사과가 몇 개 남았을까요?
A: 

# output
A: 정답은 25개 입니다
```
- 정답을 내기 위한 포맷을 제공
- 산술 연산을 시키는 구조, 올바르지 않음

#### 올바른 예시
```md
# prompt
Q: 철수는 테니스공 5개를 가지고 있습니다. 철수는 테니스공을 담은 통을 2개 더 샀는데, 각 통에는 테니스 3개가 있습니다. 철수는 이제 몇 개의 테니스공을 가지고 있을까요?

**A: 철수는 처음에 테니스공 5개를 가지고 있었습니다. 통 하나에 테니스공 3개씩 들어있는 통을 2개 샀으니, 총 6개의 테니스공이 추가 됩니다. 5+ 6= 11. 따라서 답은 11개입니다.**

Q: 식당에 사과가 23개 있었습니다. 점심을 만들기 위해 20개를 사용하고 6개를 더 샀습니 다. 그 후에 3개를 먹었다면, 사과가 몇 개 남았을까요?
A:

# output
기존에 사과가 23개 있었고, 점심을 만들기 위해 20개를 사용하고 6개를 더 샀습니다. 그 후에 3개를 먹었다면, 사과가 남았을 것입니다. 따라서 답은 23+ 6- 20-3= 6개입니다.
```
- 예시에 대한 대답을
  - 답을 내는 과정을 제공함
- 주어진 답에 대한 추론 과정에 맞게 LLM이 답하게 됨

### Zero-shot CoT
- 다음 문구를 마지막에 추가하여
  - CoT 예제를 제공하는 것과 같은 효과
  - 성능 향상
- 문구
  ```md
  Let's think step by step
  단계별로 생각해봅시다
  차근차근 생각해봅시다
  ```
- 기초적인 문제 풀이에 효과적

#### 예시
```md
# prompt
Q: 식당에 사과가 23개 있었습니다. 점심을 만들기 위해 20개를 사용하고 6개를 더 샀습니 다. 그 후에 3개를 먹었다면, 사과가 몇 개 남았을까요? 단계별로 생각해봅시다
A:

# output
1. 처음에는 식당에 사과가 23개 있었습니다.
2. 점심을 만들기 위해 20개를 사용했으므로, 남은 사과는 23- 20= 3개입니다.
3. 그 후에 6개를 더 사서 현재 사과의 개수는 3+ 6= 9개입니다.
4. 마지막으로 3개를 먹었으므로, 남은 사과의 개수는 9-3= 6개입니다.
```

#### 특징
- Open AI Chat 형식의 경우
  - **Zero-shot CoT으로 대답하도록 하는 것이 기본으로 적용**되어 있음
- 어떤 경우는 오히려 성능 하락이 될 수 있기 때문에
  - **해당 문제를 풀기 위한 적절한 방법이 맞는지 여러 샘플로 확인 필요**

### Self Consistency
- 여러가지 방식의 CoT를 제공
- 이를 통해서 다양한 추론 방식을 거침
- 그 중에서 가장 일관된 답을 선택하는 방법
- LLM이 여러번 추론을 하면서 랜덤 경로 선택하여 답을 선택
- 파라미터가 많은 모델일 수록 잘 동작
- 논문에 따르면 20개 정도의 예시를 제공하는게 제일 성능이 좋았음
- 추론 경로를 최대한 다양하게 제공해야 하므로
  - **토큰 수를 많이 사용**
- 결과 취합을 위한 **후처리** 필요

#### 예시
- Q, A 하나씩이 모두 CoT
```md
# prompt
Q: 숲에는 나무가 15그루 있습니다. 숲에서 일하는 사람들이 오늘 숲에 나무를 심을 예정입니다. 그들이 일을 마친 후, 숲에는 나무가 21그루 있을 것입니다. 숲에서 일 하는 사람들이 오늘 몇 그루의 나무를 심었을까요?
A: 처음에는 나무가 15그루 있었습니다. 나중에는 나무가 21그루 있습니다. 차이는 심은 나무의 수여야 합니다. 그러므로, 그들은 21-15=6그루의 나무를 심었어야 합니다. 답은 6입니다.
Q. 주차장에 차가 3대 있고 2대의 차가 더 도착하면, 주차장에는 몇 대의 차가 있을까요?
A: 주차장에 이미 차가 3대 있습니다. 2대가 더 도착합니다. 이제 차는 3+ 2=5대 있습니다. 답은 5입니다.
Q: 리아는 초콜릿을 32개 가지고 있었고 그녀의 여동생은 42개를 가지고 있었습니다. 그들이 35개를 먹었다면, 총 몇 조각이 남아 있을까요?
A: 리아는 초콜릿을 32개 가지고 있었고 리아의 여동생은 42개를 가지고 있었습니다. 그래서 원래 초콜릿은 32+ 42= 74조각 있었습니다. 35조각이 먹혔습니다. 그 래서 총 74-35=39조각의 초콜릿이 아직 남아 있습니다. 답은 39입니다.
Q: 제이슨은 롤리팝 20개를 가지고 있었습니다. 그는 데니에게 몇 개의 롤리팝을 줬습니다. 이제 제이슨은 롤리팝 12개를 가지고 있습니다. 제이슨은 데니에게 몇 개 의 롤리팝을 줬을까요?
A: 제이슨은 롤리팝 20개를 가지고 있었습니다. 이제 그는 12개밖에 없으니, 나머지를 데니에게 준 것이어야 합니다. 그가 데니에게 준 롤리팝의 수는 20-12= 8개이 어야 합니다. 답은 8입니다.
Q. 손은 장난감을 5개 가지고 있습니다. 크리스마스에, 그는 엄마와 아빠 각각으로부터 장난감을 2개씩 받았습니다. 그는 이제 몇 개의 장난감을 가지고 있을까요?
A: 그는 장난감 5개를 가지고 있었습니다. 그는 엄마로부터 2개를 받았으므로, 그 후에는 5+ 2= 7개의 장난감을 가지게 됩니다. 그 다음에 아빠로부터 2개를 더 받았 으므로, 총 7+2=9개의 장난감을 가지게 됩니다. 답은 9입니다.
Q: 서버룸에는 컴퓨터가 9대 있었습니다. 월요일부터 목요일까지 매일 5대의 컴퓨터가 추가로 설치되었습니다. 이제 서버룸에는 몇 대의 컴퓨터가 있을까요?
A: 월요일부터 목요일까지는 4일입니다. 매일 5대의 컴퓨터가 추가되었습니다. 그러므로 총 4* 5= 20대의 컴퓨터가 추가되었습니다. 처음에는 컴퓨터가 9대 있었으 므로, 이제는 9+ 20=29대의 컴퓨터가 있습니다. 답은 29입니다.

# Output(여러번 수행)
## Try 1
식당에 사과가 23개 있었고, 점심을 만들기 위해 20개를 사용하고 6개를 더 샀습니다.
그런 다음, 3개는 먹었습니다. 그래서 사과가 총 23+ 6-20-3= 6개 남아 있습니다.
**답은 6입니다.**

## Try 2
식당에 사과가 23개 있었고, 점심을 만들기 위해 20개를 사용했습니다. 그리고 더 6개를 샀습 니다. 그 후에 사과 3개를 먹었습니다. 이제 사과가 몇 개 남았는지 계산해 보겠습니다.
사과가 23개 있었고, 점심을 만들기 위해 20개를 사용하였고, 더 6개를 샀습니다. 따라서 총 23+ 6= 29개의 사과가 있었습니다. 그리고 3개를 먹었으므로 이제 총 29-3= 26개의 사과 가 남아 있습니다. **답은 26입니다.**

## Try 3
A: 그들은 식당에 사과가 23개 있었고, 점심을 만들기 위해 20개를 사용하고 6개를 더 샀을 것입니다. 그리고 3개를 먹었습니다. 이는 사과가 23+ 6- 20-3= 6개 남아 있다는 것을 의미합니다. **답은 6입니다**
```
- 여러 사칙연산 하는 방법에 대한 CoT를 제공
- 실행할때마다 여러 CoT중 하나의 방식을 선택하여 답을 제공함
- 이 결과들을 보고 가장 많은 답이 나온 **답은 6입니다**를 선택


### Selection Inference
- 복잡한 문제를 해결하기 위해
  - 여러 추론 단계를 연결하는 방법
- 선택과 추론을 반복하면서
  - 일련의 원인과 결과의 추론 관계를 생성하여 최종 답변을 이끌어 냄
- Context에서 질문에 답할 수 있는 부분을 선택한 뒤
  - 그 선택한 정보를 기반으로 답변
- 추론의 흔적이 남기 때문에, **인과의 과정이 남음**
  - 디버깅하기 쉬움
- 논문에서는, 반복적으로 여러번 사용하라고 권장함
  - 이를 실사용 케이스에 적용하려면
  - 추론 단계를 생성하고 종료하는 것을 세심하게 구현해야 함


#### 예시
```md
# Context
Context:
만약 누군가가 조용하다면, 그들은 흰색입니다.
만약 누군가가 젊고 빨갛다면, 그들은 흰색입니다.
젊은 사람들은 친절합니다.
만약 누군가가 친절하다면, 그들은 둥급니다.
모든 조용한 사람들은 젊습니다.
빨갛고, 큰 사람들은 친절합니다.
둥근, 빨간 사람들은 흰색입니다.
만약 누군가가 둥글다면, 그들은 조용합니다.
해리는 젊습니다.
밥은 빨강입니다.
밥은 큽니다.

# Selection(문제와 연관될 부분만 따로 제공)
해리는 젊습니다., 모든 조용한 사람들은 젊습니다., 만약 누군가가 조용하다면, 그들은 흰색입니다

# Question
Selection의 내용에 기반해 Question에 대해 답하세요.
이것은 "해리는 조용하지 않다"라는 문장 이 참인지를 암시하나요?

# Answer
아니오, 해리는 조용하지 않다는 문장은 참이 아닙니다
```

### Least to Most
- 하나의 문제를 여러개의 하위 작업으로 분할
- "주어진 문제를 풀려면, 다음 문제를 풀어야 합니다"
  - 다음 질문의 답을 이용하여, 첫 질문에 더 정확하게 답하도록 함
- 하위 작업들을 한번에 하나씩 해결해서
  - 이전 문제의 답을 다음 문제에 활용하는 방법
- 다른 기법들에 비해 높은 성능을 보여줌
- Zero shot뿐 아니라 Self-consistency를 결합하여 사용하면
  - 더 높은 성능을 기대할 수 있음
- **CoT**와 **Selection-Inference**를 결합한 방법
  - Task를 분할 정복
  - **Autonomous Agent** 개발에 사용

#### 예시
```md
# Cycle 1
Context: 영희가 미끄럼틀 꼭대기까지 올라가는 데 4분이 걸립니다. 그녀가 내려오는 데는 1분이 걸립니다. 미끄럼틀이 15분 후에 문을 닫습니다.
Question: 그녀가 문이 닫히기 전에 몇 번 미끄러 질 수 있을까요?
**이 문제의 답을 하기 위해 먼저 풀어야 할 하위 질문을 하나 만들어주세요.**

Answer: 영희가 미끄럼틀을 한 번 오르고 내려오는 데에는 총 몇 분이 걸리나요?

# Cycle 2
Context: 영희가 미끄럼틀 꼭대기까지 올라가는 데 4분이 걸립니다. 그녀가 내려오는 데는 1분이 걸립니다. 미끄럼틀이 15분 후에 문을 닫습니다.
**영희가 미끄럼틀을 한 번 오르고 내려오는 데에는 총 몇 분이 걸리나요? 천천히 생각해 보세요.**

Answer: 영희가 미끄럼틀을 한 번 오르고 내려오는 데에는 총 5분이 걸립니다.
(4분 오르기 + 1분 내려오기= 5분)

# Cycle 3: 이전 문제의 질문/답을 활용하여 첫 질문을 다시 질문
Context: 영희가 미끄럼틀 꼭대기까지 올라가는 데 4분이 걸립니다. 그녀가 내려오는 데는 1분이 걸립니다. 미끄럼틀이 15분 후에 문을 닫습니다.
Question: 영희가 미끄럼틀을 한 번 오르고 내려 오는 데에는 총 몇 분이 걸리나요?
Answer: 영희가 미끄럼틀을 한 번 오르고 내려오 는 데에는 총 5분이 걸립니다. (4분 오르기 + 1분 내려오기= 5분)
Question: **그녀가 문이 닫히기 전에 몇 번 미끄러 질 수 있을까요? 단계적으로 생각해보세요**

Answer: 문이 닫히기까지 남은 시간은 15분입니다. 영희가 미끄럼틀을 오르고 내려오는 데에는 5분이 걸 리므로, 15분을 5분으로 나누면 3번 미끄러질 수 있습니다.
```

### ReAct
- 실행 계획을 유도하고 추적
- 작업별로 실행할 액션을 선택하고 실행
- 외부 API와 상호작용하여 검색엔진을 통해 신뢰할 수 있는 정보를 사용하거나,
  - 계산기나 이미지 생성 등의 도구 사용 가능
- 실제 툴을 사용해서 정보를 주입하지 않아도
  - **Wekipedia 검색**을 시뮬레이션 하는 것만으로도 성능 향상 가능
- 실제 툴을 사용하도록 할 때는,
  - **각 단계별로 끊어서 결과를 출력하도록 제어 필요**
- 기본 프롬프트가 매우 길어지므로 **토큰 제어**에 유의할 필요가 있음

#### 예시
- 두개의 정보를 같이 제공함
```md
# Info 1
생각, 행동, 관찰 단계를 번갈아 가며 질문 응답 작업을 해결합니다. 생각은 현재 상황에 대해 추론할 수 있고, 행동은 세 가지 유형이 있습니다:
(1) Search[entity], 이는 위키백과에서 정확한 엔티티를 검색하고 존재하는 경우 첫 번째 문단을 반환합니다. 존재하지 않는 경우, 검색할 수 있는 유사한 엔티티를 반환합니다.
(2) Lookup[keyword], 이는 현재 문단에서 키워드를 포함하는 다음 문장을 반환합니
(3) Finish[answer], 이는 답을 반환하고 작업을 마칩니다.

# Info 2
다음은 몇 가지 예입니다.
---
질문: 콜로라도 주 오로제니의 동쪽 부분이 확장되는 지역의 고도 범위는 어떻게 되나요?
생각 1: 콜로라도 주 오로제니를 검색하고, 콜로라도 주 오로제니의 동쪽 부분이 확장되는 지역을 찾은 다음, 그 지역의 고도 범위를 찾아야 합니다.
**행동 1: Search[콜로라도 주 오로제니]**

관찰 1: 콜로라도 주 오로제니는 콜로라도 주와 주변 지역에서 산맥 형성(오로제니)의 한 단계였 습니다.
생각 2:동쪽 부분에 대해 언급하지 않았습니다. 그래서 동쪽 부분을 찾아봐야 합니다.
**행동 2:Lookup[동쪽 부분]**

관찰 2 (결과 1/ 1) 동쪽 부분은 고원 지대로 확장되며 이를 중앙 평원 오로제니라고 합니다.
생각 3: 콜로라도 오로제니의 동쪽 부분은 고원 지대로 확장됩니다. 따라서 고원 지대를 검색하고 그 고도 범위를 찾아야 합니다.
**행동 3: Search[고원 지대]**

관찰 3: 고원 지대는 두 가지 명확한 땅의 지역 중 하나를 가리킵니다:
생각 4: 대신 고원 지대 (미국)을 검색해야 합니다.
**행동 4: Search[고원 지대 (미국)]**

관찰 4: 고원 지대는 대평원의 부분지역입니다. 동쪽에서 서쪽으로, 고원 지대의 고도는 약 1800t에서 7,000ft (550m에서 2130m로 상승합니다.[3] 
생각 5: 고원 지대는 고도가 약 1800ft에서 7,000t로 상승하므로, 답은 1,8001t에서 7,000ft입니다.
**행동 5: Finish[1,800ft에서 7,000t]**
```
- 이후 실제 질문을 하면 다음과 같이 진행
```md
# Question
대한민국의 서울 인구는 몇명인가요?

# Answer
생각 1: 대한민국의 서울 인구를 찾아야 합니다.
**행동 1: Search[대한민국 서울 인구]**
관찰 1: 대한민국 서울의 인구는 약 10,000,000명입니다.
생각 2: 대한민국의 서울 인구는 약 10,000,000명입니다.
**행동 2: Finish[약 10,000,000명]**
```

### Self Evaluation
- LLM의 생성한 결과를 LLM이 평가하는 방법
  - 오류를 잡거나 결과를 향상시키는 방법
- Dataset 생성 자동화, RAHF의 AI 피드백, 프롬프트 평가 자동화에 사용
- 구체적인 프레임워크가 존재하지 x
- **스스로 평가**하는 컨셉으로
  - Self Critique, Constitutional AI 등 다양한 응용방식이 있음
- 장기적으로는 Automatic Prompt Engineer, Autonomous Agent 등
  - **AI가 스스로 결과를 평가하고 향상시키는 방법이 가장 중요한 방법론 중 하나가 될 것**으로 예상
- 단, GPT-4 수준의 성능을 가진 LLM으로만 의미 있는 평가가 가능하므로
  - **당분간은 사용범위에 상당한 제약이 있음**

#### 예시
```md
# Cycle 1
9+10X3 을 계산하세요.
다음 포맷으로 답변하세요.
Answer: {number}

Answer: 27

# Cycle 2
답변을 맞게 했는지 단계적으로 생각해보세요.
당신의 답변이 틀렸다면 틀린 이유를 설명하세요.
설명만 작성하세요. 그 외의 부가적인 말은 하지 마세요

Answer:
9+ 10x 3을 계산하는 과정은 다음과 같습니다:
1. 곱셈을 먼저 계산합니다. 10x3=30
2. 덧셈을 계산합니다. 9+ 30=39 따라서, 정답은 39입니다

# Cycle 3
당신의 평가를 참고하여 처음 질문에 대한 답변을 다시 하세요.
다음 포맷으로 답변하세요.
Answer: (number}

Answer: 39
```
