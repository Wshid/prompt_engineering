## [CH06_01] 적합한 모델 선택하기 

### 모델 선택 기준
- 비용
- 속도
- 정확도(성능)
- 경향성
- 안전성
- API 안정성
- 보안

### 비용, 속도, 정확도의 상관관계
- 정확도와 비용은 비례
  - 정확도를 조금만 높히려고 해도, 비용은 급수적으로 증가
- 정확도와 속도는 반비례
- 비용과 속도 역시 반비례

### 비용
- 입력 토큰 수, 출력 토큰 수에 따라 책정
- 프롬프트에 대한 가격보다
  - 생성한 토큰의 가격이 보통 2배정도 비쌈
  - 생성 결과가 길어져야 하는 경우, 비용 수준이 커짐
- 미리 비용을 정확하게 측정하려면
  - **샘플 결과**를 모아서 **tokenizer**로 계산
- 모델마다 tokenizer가 다르기 때문에
  - 모델에 부합한 tokenizer를 사용하도록 함

### GPT와 다른 모델의 정확도
- 모델의 성능을 비교하는 리더보드는 찾아보면 많음
- 참조하기엔 좋지만 신뢰하지는 말 것
- **벤치마크**마다 강점이 있는 모델이 따로 있는 경우가 많음
- 각 벤치마크의 **점수가 높다고 하더라도**
  - 실제 사례에서는 원하는 만큼 **성능이 안 나오는 경우가 많음**
- 2023.07.01 기준
  - GPT-4, gpt-3.5-turbo, Claude 정도가 다목적으로 실사용 가능
- 높은 성능이 빠르게 대중화 되는 추세
  - 다른 모델들의 성능이 어느정도 좋아지는지 계속 트래킹할 필요는 있음

### 경향성
- 모델 선택시 **정확한 정보 제공이 필요한 것이 아니면** 경향성을 보고 판단
- `gpt-3.5-turbo`의 경우
  - **구어체**의 채팅형에 최적화하여 튜닝
- `GPT-4`는 어느정도 구조화 된 리포트 형태로 생성하는 경향이 있음
- **모델이 업데이트 될 때마다 경향성이 약간씩 변경**되므로
  - 지속적으로 모니터링 필요

### 정확도, 경향성
- 벤치마크 점수를 믿지 x
- 두어번의 테스트로 결정 x
- **실제 사례를 충분히 모아 테스트를 해보고 결정**

### 안전성
- 폭력적이거나 비윤리적인 답변을 못하게 막는 장치가 있는지 확인
- OpenAI의 경우 Moderations API를 제공
- MS Azure의 경우 **기본적으로 컨텐츠 필터링**이 적용되어 있으며,
  - 해제를 원하면 승인을 받아야 함

### API 안정성
- OpenAI보다 MS가 조금 더 안정성이 높다는 의견 존재
  - 하지만 모델이 업데이트 될 때 초반에는 한동안 안정성이 급격히 떨어지는 경우 존재
- LLM이 매우 큰 규모의 컴퓨팅 자원을 사용하는 만큼
  - **아직 대부분 안정성이 높지 않음**
- 실서비스 적용시 **Failover**등의 정책을 면밀히 고려해야 함

### 보안
- OpenAI와 MS Azure 및 거의 모든 LLM 관련 회사에서
  - **API**로 들어오는 데이터는 학습에 사용하지 않음
  - but, 챗봇 서비스는 대부분 학습에 사용
- 단, 악의적인 공격이나 비윤리적 사용을 방지하기 위해
  - 대부분 `30일간 로그`를 남겨 놓고 있다고 함
- Azure등의 경우 요청하면 로그를 남기지 않는 정책도 존재
- OpenAI의 경우 **뽀안키**외에 **다른 보안 체계**를 제공하지 않으므로
  - 보안에 민감한 서비스를 제공한다면 Azure나 GCP 등
  - 사설 네트워크를 제공하는 서비스를 사용하는 것이 좋음
- 즉, 기존에 **클라우드 서버**를 사용하고 있는 회사라면,
  - 거의 동일한 보안 정책으로 **LLM API**를 사용할 수 있으므로 크게 걱정할 필요는 없음
- 극도로 민감한 데이터를 사용해 격리된 온프레미스 네트워크 환경을 필요로 한다면
  - **Custom LLM**을 사용해야 함
- 단, Custom LLM의 경우
  - 학습 비용도 크지만
  - **운영비용이 매우 크거나 비효율적일 것**이므로 면밀하게 예상 비용 계싼 필요
- 또한 클라우드형 LLM보다 **다목적 용도**로는 성능이 매우 떨어질 것이므로,
  - 사용처에 따른 비용 효율과 성능에 대한 평가를
  - 많은 시간과 비용을 들여 진행할 필요가 있음
