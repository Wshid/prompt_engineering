## [CH05_02] 생성 조건 이해하기

### Token
- 언어 모델에 입력하거나 출력하는 텍스트의 구성 요소
- 단어뿐 아니라 공백도 포함
- 하나의 단어더라도, 내부적으로 여러 토큰으로 쪼개질 수 있음
  - e.g. apples -> app + les 등
- 해당 단어들은 LLM에 들어갈때, 문자열 형태가 아닌
  - Token ID 형태로 들어가게 됨
  ```md
  I love apple.

  Tokens: 4, Characters: 13
  [40, 1842, 17180, 13]
  ```
- 토큰을 분리하는 방법
  - BPE
    - 문장/단어에 있는 글자를 적절하게 나누고
    - 빈도가 높은 글자 조합을 token으로 사용
  - 한글의 경우, 영어처럼 구성이 안되어 있기 때문에
    - byte단위로 쪼개다보니, 글자가 깨질 수 있음
- 단어, 글자도 어떤 tokenizer를 쓰느냐에 따라 token 수가 결정됨
  - GPT의 경우 단어당 1.3개의 token
  - 한글은 글자당 2.5개의 token 사용
  - 영어문서보다 한글 문서가 4~5배 정도 많이 사용하게 됨

#### Token을 활용하는 방법
- 현재 대다수의 LLM의 경우
  - 한글에 대한 토큰 사용이 상당히 비효율적
- **프롬프트를 영어로 작성**
  - 프롬프트와 출력을 영어로 작성하는 경우, 성능이 더 향상되는 경우가 있음
- **입출력을 번역하여 사용**
  - 프롬프트에 포함시킬 컨텍스트를 번역하여 사용
  - 출력을 영어로 출력시킨 후 번역하여 사용
  - 단, 고유명사 등을 출력할 필요가 없는 경우에만 사용 가능
  - 번역 품질과 번역시의 비용 및 속도 함께 고려 필요

### Context Window
- 문맥을 판단하거나 다음 단어를 예측하기 위해 참고할 토큰 범위
- 언어 모델이 다룰 수 있는 **최대 토큰 수**를 말하기도 함
  - <The quick brown fox jumps> over the lazy dog
  - The <quick brown fox jumps over> the lazy dog
- 모델마다 다름
  - GPT-3: 2,049
  - GPT-4 32K: 32,769
  - Claude 100K: 100,000

### 주요 생성 옵션
- **Temperature**
- Top P, Top K
- **Maximum length**
- Frequency Penalty
- Presence Penalty
- Stop sequence
- Injection Start

#### Temperature
- 모델이 다음 토큰 후보 중에서 **출력할 토큰을 선택**하는 방식
- `0.8`과 같은 높은 값은 출력을 더 다양하게 만듦
- `0.2`와 같은 낮은 값은 출력을 더 높은 확률의 토큰에 집중, **결정론적**으로 만듦
- **값이 높을 수록 더 창의적인 답변**
- **값이 낮을 수록 일관된 답변**
- 범위는 모델마다 다르나, Chat 모델의 경우 0~2 사이의 값

#### Top P, Top K
- 모델이 다음 토큰 **후보**를 선택하는 방식
- 확률이 상위 `P%`인 토큰
  - 혹은 확률이 상위 `K`개인 토큰의 결과를 출력 후보로 선택
- 일반적으로 Temperature만 변경하지만
  - Temperature를 **매우 높게 했을 때 결과가 무너지는 것을 방지하기 위함**
  - 맥락을 크게 벗어나거나 잘못된 글자 출력을 방지

#### Maximum Length
- 생성할 **최대 토큰 수**를 설정
- 입력한 토큰(프롬프트)과 최대 토큰 수가
  - **모델의 최대 토큰 수**를 넘지 않도록 주의 깊게 설정해야 함
- `입력 가능한 프롬프트 토큰 수 = 모델의 최대 토큰 수 - Maximum length`
  - e.g. gpt-3.5-turbo의 경우, maximum length를 1,000으로 설정시,
  - 입력 가능한 프롬프트 최대 토큰 수는 `4,096 - 1,000 = 3,096`개

#### Frequency Penalty
- 같은 토큰을 반복하면 패널티
- 같은 표현을 반복하게 되면, 이 값에 높은 값을 주어 같은 값을 반복되지 않도록 제한

#### Presence Penalty
- **한 번 이상 샘플링 된 토큰에 패널티**를 주는 파라미터
- 이 값이 **높을수록, 동일한 개념이나 아이디어를 반복적으로 사용하는 것을 방지**하여
  - 새로운 아이디어나 개념을 생성하도록 유도
- 단, 이 패널티를를 **너무 높게 설정하면**
  - 모델의 출력이 **일관성이 없거나 관련성이 떨어질 수 있음**

#### Stop sequence
- 특정 문구를 설정하고, 해당 문구가 나오면 생성을 중단
- 무의미한 반복, 반복되는 sequence 제어
- 요즘은 LLM의 성능이 좋아져서, 많이 쓰지 않는 옵션

### Injection Start
- 생성 시작 전, **특정한 문구를 삽입하고 생성을 시작**
- 다음 **생성 결과를 원하는대로 유도**할 수 있음
- 예시
  ```md
  User: 안녕?
  반가워
  ```
    - Assistant의 답변을 원했지만, 사용자의 인사를 완성하라는 의도로 이해하여, 인사의 다음 단어 생성
  ```md
  User: 안녕?
  Assistant: 안녕하세요?
  ```
  - `Assistant:`를 Injection Start로 등록
  - 생성 전에 `Assistant:` 단어를 추가하여, 의도에 맞게 Assistant의 답변을 생성
