## [CH08_02] 주요 라이브러리 소개

### 유명한 라이브러리
- LangChain
- LamaIndex
- Bursel AI SDK
- Guidance

### LangChain
- 언어 모델을 활용한 app을 빠르게 개발할 수 있도록
  - **언어 모델 어플리케이션 개발에 필요한 각종 기능을 통합하여 제공**하는 라이브러리

### LangChain Modules

#### LLM: 언어모델 Wrapper
- 여러가지 LLM을 동일한 인터페이스로 호출 가능
```python
from langchain.llms import OpenAI
llm = OpenAI(model_name="gpt-3.5-turbo", temperature=0)
llm("안녕, 세계!")
```

#### Prompt: 프롬프트 템플릿을 작성하고, 변수들을 조합하는 모듈
```python
from langchain import PromptTemplate

template = """
안녕, {target}!
"""

prompt = PromptTemplate(
  input_variables=["target"],
  template=template,
)

prompt.format(target="세계")
```

#### Memory: 대화 히스토리 구성 모듈
- 사용자의 히스토리를 저장하고 그것을 꺼내와서 사용
```python
from langchain.memory import ChatMessageHistory

history = ChatMessageHistory()

history.add_user_message("안녕, AI!")
history.add_ai_message("안녕, 인간!")

...

[HumanMessage(content='안녕, AI!', additional_kwargs={}),
AIMessage(content='안녕, 인간!', additional_kwargs={})]
```

#### Chain
- 여러가지 프롬프트를 체이닝
- 여러 LLM 호출을 연결하는 모듈
- 하나의 결과를 다른 결과로 연결하여
  - 복잡한 task를 수행할 수 있도록 하는 모듈
```python
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.chains import SimpleSequentialChain
from langchain prompts import PromptTemplate

llm = ChatOpenAI (model_name="gpt-3.5-turbo", temperature=0.7)

template="다음을 그대로 따라해 \n안녕, {target}!"

prompt_template = PromptTemplate(
  input_variables=["target"],
  template=template
)

# chain_1의 결과를 chain_2로 사용
chain_1 = LLMChain(llm=llm, prompt=prompt_template)
chain_2 = LLMChain(llm=llm, prompt=prompt_template)

chains = SimpleSequentialChain(
  chains=[chain_1, chain_2], 
  verbose=True
)

review = chains.run("세계")
```

#### Agents: 사용자 입력에 따라 미리 정해진 LLM/기타 도구 호출
- 사용자의 입력에 따라 달라지는 로직을 처리
- 여러 가지 기능들을 조합하여 쉽게 어플리케이션 만들기 가능
```python
from langchain.agents import load_tools
from langchain.agents import initialize_agent 
from langchain.agents import AgentType 
from langchain.llms import OpenAI
Ilm = OpenAI (temperature=0)
tools = load_tools(["llm-math"], llm=llm)
agent = initialize_agent(tools, llm,
  agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, 
  verbose=True)
agent.run("10 더하기 10은?")
```
- 미리 다양한 액션을 복합적으로 실행하는 에이전트를 만듦
- 툴을 사용한 에이전트라면, 특정한 툴을 여러개 넣어주고
  - 그 툴을 사용하여 결과 반환

#### Document Loaders, Text Splitter: 문서 파일 로딩 및 문서를 적절한 청크로 자름
- LLM Context 정보 제공을 위해 다양한 파일 로딩
```python
from langchain.document_loaders import DirectoryLoader 
from langchain. text_splitter import RecursiveCharacterTextSplitter

directory = '/content/data' # (.txt, pdf)

loader = DirectoryLoader(directory)
documents = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)
docs = text_splitter.split_documents(documents)
```
- 문서를 로딩하고 문서를 적절한 청크로 자르는 것이
  - 어떤 경우에는 prompt를 만드는것보다 더 많은 시간이 소요될 수 있음
- 파일 형식이나 문서의 형식에 따라 공통 사용이 가능하기 때문에
  - 다양한 경우에 쉽게 사용할 수 있도록 랭체인 구성

#### Vector Stores: Vector DB Wrapper
```python
from langchain.embeddings.openai import OpenAIEmbeddings 
from langchain.vectorstores import Pinecone

embeddings = OpenAIEmbeddings(model_name="ada")

query_result = embeddings.embed_query("Hello world")

pinecone.init(
  api_key="<pinecone api key>",
  environment="<env>"
)

index_name = "langchain-test"

index = Pinecone.from_documents(docs, embeddings, index_name=index_name)
```
- pinecone이나 croma db 같은 것을이 Interation 되어 있음
- 여러가지 Vector DB를 동일한 인터페이스로 사용 가능

#### QA Chain with Vector Stores
```python
from langchain.llm import OpenAI 
from langchain.chains.question_answering import load_qa_chain

llm = OpenAI(model_name="text-davinci-003")
chain = load_qa_chain(llm, chain_type="stuff")
similar_docs = index.similarity_search(query, k=5)
query= "질문"
answer = chain.run(input_documents=similar_docs, question=query)
```
- 사용할 LLM과 Vector store만 잘 설정하면
  - 간단한 코드로 **질문 답변을 쉽게 만들어낼 수 있음**

### LangChain Problems
- 구조 복잡도에 비해 **문서가 부족, 구현이 깔끔하지 않음**
- 대부분의 모듈이 있는 타 라이브러리나 서비스 Wrapper에 불과하여
  - **간단한 작업을 복잡하게 만들고**
  - **프롬프트 구현이 숨겨져 있어 디버깅을 어렵게 만듦**
- 프로토타입 개발에는 유용하나, **프로덕션에 사용하기엔 지양함** 
- 실제 강사는
  - 프로토타입에서 활용하지 않음
  - LangChain 모듈 안에 있는 **구현**이나 **프롬프트**를 참고하기 위한 코드를 볼때 사용
